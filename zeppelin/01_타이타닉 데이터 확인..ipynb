{
  "metadata": {
    "name": "01_타이타닉 데이터 확인",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.sql import SparkSession\nspark \u003d SparkSession.builder.appName(\u0027spark-dataframe\u0027).getOrCreate()\nspark"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfilepath \u003d \u0027file:////home/ubuntu/working/spark-examples/data/titanic_train.csv\u0027\n\n# inferSchema\u003dTrue : \ntitanic_sdf \u003d spark.read.csv(filepath, inferSchema \u003d True, header \u003d True)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nz.show(titanic_sdf)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n\ntitanic_df_describe \u003d titanic_sdf.select([\u0027Parch\u0027]).describe()\nz.show(titanic_df)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\ntitanic_final_data \u003d titanic_sdf.select([\u0027Survived\u0027, \u0027Pclass\u0027, \u0027Sex\u0027, \u0027Age\u0027, \u0027SibSp\u0027, \u0027Parch\u0027, \u0027Fare\u0027,\u0027\u0027,\u0027PassengerId\u0027])\r\nz.show(titanic_final_data)\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ntitanic_final_data.createOrReplaceTempView(\"titanic_final\")"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nquery \u003d \u0027\u0027\u0027\nSELECT\n    COUNT(Survived) \nFROM titanic_final\nWHERE Survived \u003d 1;\n\u0027\u0027\u0027\n\nz.show(spark.sql(query))"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nquery \u003d \u0027\u0027\u0027\r\nSELECT\r\n    COUNT(Survived) AS Survived_female\r\nFROM titanic_final\r\nWHERE Survived \u003d 1 AND Sex \u003d \u0027female\u0027;\r\n\u0027\u0027\u0027\r\n\r\nz.show(spark.sql(query))"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nquery \u003d \u0027\u0027\u0027\nSELECT \n    sex, \n    COUNT(PassengerId), \n    SUM(Survived), \n    (CAST(SUM(Survived) AS FLOAT) / COUNT(PassengerId)) \nFROM titanic_final\nGROUP BY 1;\n\u0027\u0027\u0027\n\nz.show(spark.sql(query))"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nquery \u003d \u0027\u0027\u0027\nSELECT\n    SibSp,\n    COUNT(*) AS TotalPassengers,\n    SUM(Survived) AS TotalSurvived,\n    AVG(Survived) AS SurvivalRate\nFROM titanic_final\nGROUP BY SibSp\nORDER BY SibSp;\n\u0027\u0027\u0027\n\n.show(spark.sql(query))"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nquery \u003d \u0027\u0027\u0027\nSELECT\n    Parch,\n    COUNT(*) AS TotalPassengers,\n    SUM(Survived) AS TotalSurvived,\n    AVG(Survived) AS SurvivalRate\nFROM titanic_final\nGROUP BY Parch\nORDER BY Parch;\n\u0027\u0027\u0027\n\nz.show(spark.sql(query))"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\n\r\n# 등급 별 승객 인원\r\nquery \u003d \u0027\u0027\u0027\r\nSELECT\r\n    Pclass, \r\n    COUNT(Pclass) \r\nFROM titanic_final\r\nGROUP BY Pclass;\r\n\r\n\u0027\u0027\u0027\r\n\r\nz.show(spark.sql(query))"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nquery \u003d \u0027\u0027\u0027\nSELECT\n    Pclass,\n    Count(Pclass)\nFROM titanic_final\nWHERE Survived \u003d 1\nGROUP BY Pclass;\n\u0027\u0027\u0027\n\nz.show(spark.sql(query))"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nspark.stop()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}